#+title: Concurrency
* The Dialogue between Prof and student
So, what is concurrency, my professor?

Imagine we have a peach --

There are alot of peaches on a table, and a lot of people who wish to eat them.
Let's say we did it this way:

Each eater first identifies a peach visually, and then tires to grab it and eat it. *What's wrong with this approach?*

You might see a peach that somebody else also sees. If they get there first, when you reach out, no peach for you.

S0 what we should do?

A better way of going about this. Maybe /Maybe form a line, and when you get to the front, grab a peach and get on with it/

But what's wrong about this approach? *

Do I need to do all the work?
Yes.

We used to have many people grabbing for peaches all at once, which is faster. But in my way, we just go one at a time, which is correct but quite a bit slower.

*The best kind of approach would be fast & correct, probably.*

As it turns out, there are certain types of programs that we call /multi-threaded/ applications. 

Each *thread* is kind of like an independent agent running around in this program, doing things on the program's behalf. 

*Thread* access memory, like the peaches we talked about beofore.

If we don't coordinate access to memory between threads, the program won't work as expected.

Why this is OS related? Isn't this /application programming/? 
*Reasons:*
1) OS must support multi-threaded applications with promitives such as *lock* & *condition variables*.

2) The *OS itself* was the first concurrent program -- it must access its own memory very carefully or many strange and terrible things will happen. It can get quite grisly.(恐怖的)

* Lec12 Thread & Thread API
** Introduction to Concurrency
*** What we've done before
- Virtualize a single CPU and turn it into muliple virtual CPUs. It creates the illusion that muliple programs runs at the same time.
- Create the illusion of a large, private *virtual memory* 
*** A new abstraction for a single running program -- *thread*
A multi-threaded program has more than one point of execution.(Muliple PCs)
Each thread is *very much like* a separate process, *expect* for one difference:
/They share the same address space and thus can access the same data/


*** Structure of a Thread
A program counter that tracks where the program is fetching instructions from.

Each thread has its own private set of registers it uses for computation; thus, 
if there are two threads running on a single processor, when switching from running T1 to running T2, the *context switch* is quite similar to it in process.

With processes, we have *process control blocks*(PCBs)
Now, we'll need one or more *thread control blocks*(TCBs) to store the state of each thread of a process. 

*A Major difference:*
1. The address space remains the same(i.e. there is no need to switch which page table we are using)
2. Concerns about stack.
   A single-threaded process has a single stack. Usually resides at bottom of the address space. 
   In a multi-threaded process, each thread runs independently, then we get muliple stack in it. The stacks are spread throughout the address space. 

Any stack-allocated variables, parameters, return values, and other things that we put on the stack will be places in what is sometimes called *thread-local* storage, i.e., the stack of the relevant thread.

It makes address space quite less beautiful and it may cause some trouble. However, it's generally OK, as stack do not generally have to be very large.

*** Thread Creation
Example code:
#+begin_src c
  #include <stdio.h>
  #include <assert.h>
  #include <pthread.h>
  void *mythread(void *arg) {
      printf("%s\n", (char *) arg);
      return NULL;
  }

  int main(int argc, char *argv[]) {
    pthread_t p1, p2;
    int rc;
    printf("main: begin\n");
    // ~rc~ is just a variable to store the rv of pthread_create

    rc = pthread_create(&p1, NULL, mythread, "A"); assert(rc == 0);
    rc = pthread_create(&p2, NULL, mythread, "B"); assert(rc == 0);

  // join waits for the threads to finish
  // 
    rc = pthread_join(p1, NULL); assert(rc == 0);
    rc = pthread_join(p2, NULL); assert(rc == 0);
    printf("main: end\n");
    return 0;
  }
#+end_src
Once a thread is created, it may start running right away. (depending on the whim of the scheduler). Alternatively, it may be put in a "ready" but not "running" state and thus not run yet. 

After creating /T1/ and /T2/, the main thread then calls ~pthread_join()~, which waits for a /particular thread to complete./

There is *NO* reason to assume that *a thread that is created first* will run *first*.

Computer is much more harder to understand with concurrency.

*** Why it get worse: *Shared Data*
How thread interact with /shared data/?
Given a case that two threads wish to update a global shared data. The code is like:
#+begin_src c
  #include <stdio.h>
  #include <pthread.h>
  #include "mythreads.h"

  static volatile int counter = 0; 6
  // mythread()
  // Simply adds 1 to counter repeatedly, in a loop
  // No, this is not how you would add 10,000,000 to
  //a counter, but it shows the problem nicely.
  void * mythread(void *arg){
    printf("%s: begin\n", (char *) arg);
    int i;
    for (i = 0; i < 1e7; i++) {
      counter = counter + 1;
    }
    printf("%s: done\n", (char *) arg);
    return NULL;
  }
  //
  //main()
  // Just launches two threads (pthread_create)
  // and then waits for them (pthread_join)
  //
  int main(int argc, char *argv[]){
    pthread_t p1, p2;
    printf("main: begin (counter = %d)\n", counter);
    Pthread_create(&p1, NULL, mythread, "A");
    Pthread_create(&p2, NULL, mythread, "B");

  // join waits for the threads to finish
    Pthread_join(p1, NULL);
    Pthread_join(p2, NULL);
    printf("main: done with both (counter = %d)\n", counter);
    return 0;
  }
#+end_src

*Some notes on the code:*
1) We wrap the thread creation and join routines to simply exit on failure. We want to at least notice an error occurred(if it did), but not do anything very smart about it, like we can just exit it.

   Thus ~Pthread_create~ simply calls ~pthread_create()~ and make sure the return code is 0, if it isn't, ~Pthread_create()~ just prints a message and exits.

2) Instead of using two separate function bodies for the worker threads, we just use a single piece of code, and pass the thread an argument(/in this case, a string/) so we can have each thread print a different letter before its messages.
3) *The most importantly*, what each worker is trying to do: add a number to the shared variable ~counter~, and do so 10 million times in a loop. Thus, the *desired* final result is 2*10e7.

Compile a multi-threaded program:
~gcc -o main main.c -Wall -pthread~

Usually we cannot get out desired final result, we usually get some numbers slightly smaller than 2*10e7. *The computer cannot generate a deterministic result now*. 

*WHY DOES THIS HAPPEN???*

*** The Heart Of The Problem: *Uncontrolled Scheduling*
Wish to add ~1~ to ~counter~, the code sequence in doing this in ~x86~,
#+begin_src asm
mov address, %eax
add $0x1, %eax
mov %eax, address
#+end_src
Thing like:
When T1 enters this region of code, and counter now is 50, when finishes the increment and eax=51, *a time interrupt* happens. thus the system saves the state of the currently running thread(PC, the registers inclulding ~eax~), to the thread's TCB.

However, when T2 starts running, the ~counter~ is still 50 beacuse it don't get updated due the *evil time interrupt*. When T2 finishes, ~counter~ becomes 51. Restore the T1's state, then running it. It will run the ~mov~ 51 to the counter, which causes no increment to ~counter~ beacuse ~counter~ is already 51 by T2.

**** Race Condition
This is called *race condition*: the results depend on the timing execution of the code. With some bad luck, we get the wrong result. 

And the result is *indeterminate*.

**** Critical section
We call this code a critical section. 

A critical section is a piece of code that accesses a shared variable(or a shared source), and must not be *concurrently executed* by more than one thread.

**** Mutual Exclusion
This property guaratees that if one thread is executing within the critical section, the others will be prevented from doing so.

*Djikstra* is involved here!










 























*** The Wish For Atomicity
One way to solve this problem would be to have more powerful instructions that, in a single step, did exactly whatever we needed dont and thus removed the possibility of an untimly interrupt. 

What if we have a super instruction like this:
~memory-add 0x8049a41, $0x1~
This instruction executes *atomically*, there is no between state. 
Atomicity, means "as a unit", sometimes called "all or none"(全或無).
We want to execute the *three lines of code* above all at once. 

What we instead do is to ask the hardware for a few instructions upon which we can build a general set of what we call *synchronization primitives*. By using this and some help from the operating system, we will be able to build multi-threaded code that accesses critical sections in a synchronized and controlled manner, and thus reliably produces the correct result despite the challenging nature of concurrent execution. Cool?!

This is the problem we will study in this section of the book.






*** One More Problem: Waiting For Another
As it turns out, there is another common interaction that arises, where one thread must wait for another to complete some action before it continues. This interaction arises, for example, whn a process performs a disk IO and is put to sleep; when the I/O completes, the process needs to be broused from its slumber so it can continue.

So we will also study mechanisms to support this type of sleeping/waking interaction that is common in multi-threaded programs.
*condition variables* is about this issue. 

** CRUX: How to provide support for synchronization?
- What support do we need from the hardware in order to build useful synchronization primitives? 
- What support do we need from OS?
- How can we build these primitives correctly and efficiently?
- How can programs use them to get the desired results?


** Thread API -- Code Practice

*** CRUX: How to create and control *THREADS*
What interfaces should the OS present for thread creation and control? 
How should these interfaces be designed to enable *ease of use* as well as *utility*.
*** Thread Creation
#+begin_src c
  #include <pthread.h>
  int
  pthread_create(       pthread_t * thread,
                  const pthread_attr_t * attr,
                        void * (*start_routine)(void*),
                        void * arg);
#+end_src
- *thread*: a pointer to a structure of type ~pthread_t~, we use this structure to /interact/ with this thread, and pass it to ~pthread_create()~ to *initialize* it.
- *attr*; specify any attributes this thread might have. In most cases we put ~NULL~ here.
- ~(* start_routine)(void *)~ is the most complex but is just *asking*: which function should this thread start /running in/? We call it *function pointer* in C, and this just tells us the following is expected:
      a functin name ~start_routine~, which is passed a single argument of type ~void *~, and which returns a value of type ~void *~ (a void pointer)
- *arg*: is exactly the argument to be passed to the function where the thread begins execution. 

*** Thread Completion 
#+begin_src c
int pthread_join(pthread_t thread, void **value_ptr);
#+end_src

This is a routine.

- ~thread~: this is of type ~pthread_t~, and is used to specify which thread to wait for. The variable is initialized by the ~pthread_create()~ we talked before, if you keep it around, you can use it to wait for that thread to terminate.

- ~**value_ptr~ is a pointer to the return value you expect to get back. because the routine can return anything, it is defined to return a pointer to *void*. pthread_join() change
#+begin_src c
  #include <stdio.h>
  #include <pthread.h>
  #include <assert.h>
  #include <stdlib.h>
  typedef struct __myarg_t {
    int a;
    int b;
  } myarg_t; // input arg structure

  typedef struct __myret_t {
    int x;
    int y;
  } myret_t; //return arg structure

  void *mythread(void *arg) {
    // Declare a pointer point to the input arg
    myarg_t *m = (myarg_t *) arg;
    printf("%d %d\n", m->a, m->b);
    // Declare a return argument structure 
    myret_t *r = malloc(sizeof(myret_t));
    r->x = 1;
    r->y = 2;
    return (void *) r;
  }

  int main(int argc, char *argv[]) {
    int rc;
    pthread_t p;
    myret_t *m;
    myarg_t args;
    args.a = 10;
    args.b = 20;
    pthread_create(&p, NULL, mythread, &args);
    pthread_join(p, (void **) &m);
    printf("returned %d %d\n", m->x, m->y);
    return 0;
  }
#+end_src

When calling ~pthread_create()~ to create a thread you need a immediate ~pthread_join()~. 

In fact, a easier way to accomplish this exact task， this is called *procedure call*. Clearly, we'll usually be creating more than just one thread and wait for it to complete.

*Note*
Not all multi-threaded used the join routine.

A long-lived program may not need a join.






























*** Locks

Providing mutual exclusion（相互排斥） to a *critical section* via *locks*

#+begin_src c
int pthread_mutex_lock(pthread_mutex_t *mutex);
int pthread_mutex_unlock(pthread_mutex_t *mutex);
#+end_src
锁住正在运行的进程

When you have a region of code which is a *critical section*, and thus you need to protect it by *locks* in order to operate as desired. You acn probably imagine what the code looks like:

#+begin_src c
pthread_mutex_t lock;
pthread_mutex_lock(&lock);
x = x + 1 // or any other critical section
pthread_mutex_unlock(&look);
#+end_src

Situation 1. 
If no other thread holds the lock when ~pthread_mutex_lock()~ is called, the thread will acquire(get) the lock and enter the critical section.

Situation 2. 
If another thread does indeed holds the lock, the thread trying to grab the lock will not return form the call *until* it has acquired the lock. (When the locked-thread release the lock)

Then we have a problem: many threads may be stuck waiting inside the lock acquisition function at a given time; only the thread with the lock acquired should call unlock.

*However, the code is BROKEN*. 
1. *lack of proper initialization*
   All locks must be initialized with a correct value. 
we often use
#+begin_src c
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
#+end_src
Or, a dynamic weak:

#+begin_src c
int rc = pthread_mutex_init(&lock, NULL); 
assert(rc == 0); // check the success
#+end_src

2. It fails to check the error when calling lock and unlock.
Just like virtually any library you call in a Unix system, these routines can also fail. If the program does not handle  the error properly, the failure will happen sliently and the *lock* is invalid.

#+begin_src c
  // Use this to keep your code clean but check for failures // Only use if exiting program is OK upon failure
  void Pthread_mutex_lock(pthread_mutex_t *mutex) {
    int rc = pthread_mutex_lock(mutex);
    assert(rc == 0);
  }
#+end_src

















*** Two More Routines To Interact With Locks
#+begin_src c
  int pthread_mutex_trylock(pthread_mutex_t *mutex);
  int pthread_mutex_timedlock(pthread_mutex_t *mutex,
                              struct timespec *abs_timeout);
#+end_src
These two are used in lock *acquisition*

~trylock~ returns failure if the lock is already held;
~timedlock~ returns after a timeout or after acquiring the lock, whichever happens first. Thus, the timelock with a timeout of zero degenerates to the trylock case. Both versions should generally be avoided. 

We will talk about it later. 


*** Condition variables
They are useful when some kind signaling must take place beteween threads, if one thread is waiting for another to do something before it can continue.

Two primary routines are used by programs wishing to interact in this way:

#+begin_src c
int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex);
int pthread_cond_signal(pthread_cond_t *cond);
#+end_src

To use a condition variable, one has to in addition have a lock that is associated with this condition. When calling either of the above routines, this *lock should be held.*

1. ~pthread_cond_wait()~ puts the calling thread to sleep, and thus waits for some other thread to signal it, ususally when something in the progra has changed that the now-sleeping thread might care about. A typical usage is like:
#+begin_src c
  pthread_mutex_lock lock = PTHREAD_MUTEX_INITIALIZER;
  pthread_cond_t cond = PTHREAD_COND_INITIALIZER;

  Pthread_mutex_lock(&lock);

  while (ready == 0)
    Pthread_cond_wait(&cond, &lock);

  Pthread_mutex_unlock(&lock);
#+end_src

























